{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.morphology import remove_small_objects, remove_small_holes\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from pair_transforms import *\n",
    "from FaceDataset import FaceDataset\n",
    "\n",
    "from models.linknet import UNetResnet\n",
    "\n",
    "from loss import dice_loss\n",
    "from utils import rle_encode, write_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1491\n"
     ]
    }
   ],
   "source": [
    "path_images = list(filter(lambda x: x.endswith('.jpg'), os.listdir('data/train/')))\n",
    "print(len(path_images))\n",
    "train_images, val_images = path_images[:1460], path_images[1460:1491]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_transforms = transforms.Compose([\n",
    "    transforms.RandomGrayscale(p=0.01)\n",
    "    ])\n",
    "\n",
    "pair_transforms = Compose([\n",
    "    RandomCrop(240),\n",
    "    RandomHorizontalFlip(),\n",
    "    ToTensor()\n",
    "    ])\n",
    "\n",
    "tensor_transforms = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1460 images\n",
      "31 images\n"
     ]
    }
   ],
   "source": [
    "train_dataset = FaceDataset(\n",
    "    images_dir='data/train/',\n",
    "    images_name=train_images,\n",
    "    target_dir='data/train_mask/',\n",
    "    color_transforms=color_transforms,\n",
    "    pair_transforms=pair_transforms,\n",
    "    tensor_transforms=tensor_transforms)\n",
    "\n",
    "val_dataset = FaceDataset(\n",
    "    images_dir='data/train/',\n",
    "    images_name=val_images,\n",
    "    target_dir='data/train_mask/',\n",
    "    pair_transforms=Compose([ ToTensor() ]),\n",
    "    tensor_transforms=tensor_transforms)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "net = UNetResnet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 240, 240])\n",
      "torch.Size([2, 1, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "# Check sizes\n",
    "for batch in train_data_loader:\n",
    "    break\n",
    "    \n",
    "out = net.forward(batch['img'].cuda())\n",
    "\n",
    "print(batch['img'].shape)\n",
    "print(out.shape)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "criterion = dice_loss\n",
    "val_criterion = dice_loss\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(verbose=True):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    train_loss = 0.0\n",
    "    for i, batch in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        batch['img'], batch['mask'] = batch['img'].to(device), batch['mask'].to(device)\n",
    "        output = net(batch['img'])\n",
    "        loss = criterion(output, batch['mask'])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 99:\n",
    "            if verbose:\n",
    "                print(' [{} - {}],\\ttrain loss: {:.5}'.format(epoch+1, i+1, running_loss/100))\n",
    "            else:\n",
    "                print('|', end='', flush=True)\n",
    "            running_loss = 0.0\n",
    "    train_loss /= i\n",
    "    print('\\n [{}], \\ttrain loss: {:.5}'.format(epoch+1, train_loss))\n",
    "    return train_loss\n",
    "\n",
    "def validate():\n",
    "    net.eval()\n",
    "    val_loss = 0.0\n",
    "    for i, batch in enumerate(val_data_loader):\n",
    "        batch['img'], batch['mask'] = batch['img'].to(device), batch['mask'].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = net(batch['img'])\n",
    "        val_loss += val_criterion(output, batch['mask']).detach().item()\n",
    "    val_loss /= len(val_dataset)\n",
    "    print(' [{}], \\tval loss: {:.5}\\n'.format(epoch+1, val_loss))\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1 - 100],\ttrain loss: 0.028007\n",
      " [1 - 200],\ttrain loss: 0.03228\n",
      " [1 - 300],\ttrain loss: 0.033948\n",
      " [1 - 400],\ttrain loss: 0.031249\n",
      " [1 - 500],\ttrain loss: 0.029961\n",
      " [1 - 600],\ttrain loss: 0.031217\n",
      " [1 - 700],\ttrain loss: 0.033077\n",
      "\n",
      " [1], \ttrain loss: 0.031503\n",
      " [1], \tval loss: 0.014317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_epoch = 1\n",
    "history = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss = train()\n",
    "    val_loss = validate()\n",
    "    history.append((train_loss, val_loss))\n",
    "    #scheduler.step(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), 'models/linknet34')\n",
    "#net.load_state_dict(torch.load('models/linknet34_best'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2177 images\n"
     ]
    }
   ],
   "source": [
    "path_images = list(filter(lambda x: x.endswith('.jpg'), os.listdir('data/test/')))\n",
    "\n",
    "test_data_loader = DataLoader(\n",
    "    FaceDataset('data/test', path_images, tensor_transforms=tensor_transforms), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_images = [int(x.split('.')[0]) for x in path_images]\n",
    "\n",
    "write_results(net, test_data_loader, path_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2176\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_pseudo_labels(dir_name='data/pseudo', threshold=0.25):\n",
    "    for i,batch in enumerate(test_data_loader):\n",
    "        batch['img'] = batch['img'].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = net.forward(batch['img'])\n",
    "\n",
    "        img = output[0].detach().cpu().numpy()\n",
    "        post_img = remove_small_holes(remove_small_objects(img > threshold))\n",
    "        im = Image.fromarray(post_img[0].astype('uint8')*255)\n",
    "        im.save(\"{}/{}.png\".format(dir_name, path_images[i]))  \n",
    "    print(\"Processed {} imgs\".format(i+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
